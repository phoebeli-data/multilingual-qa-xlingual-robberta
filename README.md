# multilingual-qa-xlingual-robberta
This project evaluates Multilingual RoBERTaâ€™s ability to generalize in Question Answering across languages. By examining zero-shot cross-lingual transfer, we explore how linguistic similarity and pretraining representation affect performance, highlighting disparities in multilingual NLP and informing more equitable language technologies.
